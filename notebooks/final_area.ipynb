{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Experiment (Pain Area Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, PrecisionRecallDisplay, balanced_accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.getcwd() + '\\\\..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.load_dataset import load_dataset, load_fusioned_dataset, get_class_names\n",
    "from src.lib.time_series_augmentation.utils.augmentation import jitter, rotation\n",
    "from src.models.CNNLSTM import CNNLSTM\n",
    "from src.models.RCNN import RCNN\n",
    "from src.lib.DeepStack.deepstack.base import KerasMember\n",
    "from src.lib.DeepStack.deepstack.ensemble import DirichletEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=48)\n",
    "epochs = 100\n",
    "cnn_auc = []\n",
    "rnn_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(os.path.abspath('')).parent / 'models' / 'saved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unimodal Body (Skeleton Pose Estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset('skeleton')\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = get_class_names('skeleton')\n",
    "tmp = pd.DataFrame(classes)\n",
    "classes = tmp.value_counts()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_integers = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "d_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 CNN + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    cnnlstm_area_body_model = CNNLSTM(n_features, None, n_length, n_outputs, multiclass=True)\n",
    "    history = cnnlstm_area_body_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=32, class_weight=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        cnnlstm_area_body_model.save(model_path / 'body_area_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_cnnlstm_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "body_cnnlstm_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_cnnlstm_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "body_cnnlstm_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm_area_body_model = load_model(model_path / 'body_area_cnnlstm.h5')\n",
    "y_pred = cnnlstm_area_body_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = cnnlstm_area_body_model.evaluate(X_test, y_test)\n",
    "bal_acc = balanced_accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nBalanced Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, bal_acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall(y_test.argmax(axis=1), y_pred, plot_micro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rcnn_area_body_model = RCNN(n_features, None, n_length, n_outputs, multiclass=True)\n",
    "    history = rcnn_area_body_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=32, class_weight=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        rcnn_area_body_model.save(model_path / 'body_area_rcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_rcnn_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "body_rcnn_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_rcnn_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "body_rcnn_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_area_body_model = load_model(model_path / 'body_area_rcnn.h5')\n",
    "y_pred = rcnn_area_body_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = rcnn_area_body_model.evaluate(X_test, y_test)\n",
    "bal_acc = balanced_accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nBalanced Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, bal_acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unimodal Face (Facial Expression + Head Pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset('AUs')\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = get_class_names('AUs')\n",
    "tmp = pd.DataFrame(classes)\n",
    "classes = tmp.value_counts()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_integers = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "d_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 CNN + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    cnnlstm_area_face_model = CNNLSTM(n_features, None, n_length, n_outputs, multiclass=True)\n",
    "    history = cnnlstm_area_face_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=32, class_weight=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        cnnlstm_area_face_model.save(model_path / 'face_area_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cnnlstm_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "face_cnnlstm_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cnnlstm_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "face_cnnlstm_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm_area_face_model = load_model(model_path / 'face_area_cnnlstm.h5')\n",
    "y_pred = cnnlstm_area_face_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = cnnlstm_area_face_model.evaluate(X_test, y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rcnn_area_face_model = RCNN(n_features, None, n_length, n_outputs)\n",
    "    history = rcnn_area_face_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=32)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        rcnn_area_face_model.save(model_path / 'face_area_rcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_rcnn_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "face_rcnn_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_rcnn_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "face_rcnn_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_area_face_model = load_model(model_path / 'face_area_rcnn.h5')\n",
    "y_pred = rcnn_area_face_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = rcnn_area_face_model.evaluate(X_test, y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multimodal Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_fusioned_dataset(binary=True)\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 CNN + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    cnnlstm_area_earlyfusion_model = CNNLSTM(n_features, None, n_length, n_outputs, multiclass=True)\n",
    "    history = cnnlstm_area_earlyfusion_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=32, class_weights=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        cnnlstm_area_earlyfusion_model.save(model_path / 'early_area_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_cnnlstm_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "early_cnnlstm_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_cnnlstm_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "early_cnnlstm_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm_area_earlyfusion_model = load_model(model_path / 'early_area_cnnlstm.h5')\n",
    "y_pred = cnnlstm_area_earlyfusion_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = cnnlstm_area_earlyfusion_model.evaluate(X_test, y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rcnn_area_earlyfusion_model = RCNN(n_features, None, n_length, n_outputs, multiclass=True)\n",
    "    history = rcnn_area_earlyfusion_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=32, class_weights=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        rcnn_area_earlyfusion_model.save(model_path / 'early_area_rcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_rcnn_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "early_rcnn_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_rcnn_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "early_rcnn_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_area_earlyfusion_model = load_model(model_path / 'early_area_rcnn.h5')\n",
    "y_pred = rcnn_area_earlyfusion_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = rcnn_area_earlyfusion_model.evaluate(X_test, y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multimodal Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_X_train, body_X_test, body_y_train, body_y_test = load_dataset('skeleton', binary=True, fusion=True)\n",
    "body_X = body_X_train.copy()\n",
    "body_y = body_y_train.copy()\n",
    "\n",
    "print(body_X_train.shape, body_y_train.shape)\n",
    "print(body_X_test.shape, body_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_X_train, face_X_test, face_y_train, face_y_test = load_dataset('AUs', binary=True)\n",
    "face_X = face_X_train.copy()\n",
    "face_y = face_y_train.copy()\n",
    "\n",
    "print(face_X_train.shape, face_y_train.shape)\n",
    "print(face_X_test.shape, face_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_length, body_features, face_features, n_outputs = face_X_train.shape[2], body_X_train.shape[-1], face_X_train.shape[-1], body_y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CNN + BiLSTM (Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(body_X):\n",
    "    body_X_train, body_X_val = body_X[train_index], body_X[val_index]\n",
    "    face_X_train, face_X_val = face_X[train_index], face_X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    cnnlstm_area_latefusion_model = CNNLSTM(body_features, face_features, n_length, n_outputs, fusion=True, multiclass=True)\n",
    "    history = cnnlstm_area_latefusion_model.trainFusioned(body_X_train, face_X_train, y_train, body_X_val, face_X_val, y_val, epochs=epochs, batch_size=32, class_weights=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        cnnlstm_area_latefusion_model.save(model_path / 'late_area_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_cnnlstm_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "late_cnnlstm_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_cnnlstm_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "late_cnnlstm_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance and predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm_area_latefusion_model = load_model(model_path / 'late_area_cnnlstm.h5')\n",
    "y_pred = cnnlstm_area_latefusion_model.predict([body_X_test, face_X_test])\n",
    "_, acc, auc, precision, recall, f1 = cnnlstm_area_latefusion_model.evaluate([body_X_test, face_X_test], y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RCNN (Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_val = []\n",
    "auc = []\n",
    "auc_val = []\n",
    "precision = []\n",
    "precision_val = []\n",
    "recall = []\n",
    "recall_val = []\n",
    "f1 = []\n",
    "f1_val = []\n",
    "val_accuracy = 0.0\n",
    "for train_index, val_index in kf.split(body_X):\n",
    "    body_X_train, body_X_val = body_X[train_index], body_X[val_index]\n",
    "    face_X_train, face_X_val = face_X[train_index], face_X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rcnn_area_latefusion_model = RCNN(body_features, face_features, n_length, n_outputs, fusion=True, multiclass=True)\n",
    "    history = rcnn_area_latefusion_model.trainFusioned(body_X_train, face_X_train, y_train, body_X_val, face_X_val, y_val, epochs=epochs, batch_size=32, class_weights=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    acc.append(history.history['accuracy'][-1])\n",
    "    acc_val.append(history.history['val_accuracy'][-1])\n",
    "    f1.append(history.history['f1_score'][-1])\n",
    "    f1_val.append(history.history['val_f1_score'][-1])\n",
    "    save_model = False\n",
    "    for key in history.history.keys():\n",
    "        if 'auc' in key and not 'val' in key:\n",
    "            auc.append(history.history[key][-1])\n",
    "        elif 'auc' in key and 'val' in key:\n",
    "            auc_val.append(history.history[key][-1])\n",
    "            if history.history[key][-1] > val_accuracy:\n",
    "                val_accuracy = history.history[key][-1]\n",
    "                save_model = True\n",
    "        if 'precision' in key and not 'val' in key:\n",
    "            precision.append(history.history[key][-1])\n",
    "        elif 'precision' in key and 'val' in key:\n",
    "            precision_val.append(history.history[key][-1])\n",
    "        if 'recall' in key and not 'val' in key:\n",
    "            recall.append(history.history[key][-1])\n",
    "        elif 'recall' in key and 'val' in key:\n",
    "            recall_val.append(history.history[key][-1])\n",
    "    if save_model:\n",
    "        rcnn_area_latefusion_model.save(model_path / 'late_area_rcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_rcnn_train_results = {'Accuracy': np.average(acc), 'ROC/AUC': np.average(auc), 'Precision': np.average(precision), 'Recall': np.average(recall), 'F1-score': np.average(f1)}\n",
    "late_rcnn_train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_rcnn_val_results = {'Accuracy': np.average(acc_val), 'ROC/AUC': np.average(auc_val), 'Precision': np.average(precision_val), 'Recall': np.average(recall_val), 'F1-score': np.average(f1_val)}\n",
    "late_rcnn_val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_area_latefusion_model = load_model(model_path / 'late_area_rcnn.h5')\n",
    "y_pred = rcnn_area_latefusion_model.predict([body_X_test, face_X_test])\n",
    "_, acc, auc, precision, recall, f1 = rcnn_area_latefusion_model.evaluate([body_X_test, face_X_test], y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test.argmax(axis=1), y_pred, plot_micro=False, plot_macro=False, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_test.argmax(axis=1), y_pred, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm_body_member = KerasMember(name=\"CNN + Bidirectional LSTM Body Model\", keras_model=cnnlstm_area_body_model, train_batches=(body_X_train, y_train), val_batches=(body_X_test, body_y_test))\n",
    "rcnn_body_member = KerasMember(name=\"RCNN Body Model\", keras_model=rcnn_area_body_model, train_batches=(body_X_train, y_train), val_batches=(body_X_test, body_y_test))\n",
    "cnnlstm_face_member = KerasMember(name=\"CNN + Bidirectional LSTM Face Model\", keras_model=cnnlstm_area_face_model, train_batches=(face_X_train, y_train), val_batches=(face_X_test, face_y_test))\n",
    "rcnn_face_member = KerasMember(name=\"RCNN Face Model\", keras_model=rcnn_area_face_model, train_batches=(face_X_train, y_train), val_batches=(face_X_test, face_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichletEnsemble = DirichletEnsemble()\n",
    "dirichletEnsemble.add_member(cnnlstm_body_member)\n",
    "dirichletEnsemble.add_member(rcnn_body_member)\n",
    "dirichletEnsemble.add_member(cnnlstm_face_member)\n",
    "dirichletEnsemble.add_member(rcnn_face_member)\n",
    "dirichletEnsemble.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = dirichletEnsemble.describe()\n",
    "cnn_auc.append(round(e, 2))\n",
    "rnn_auc.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Unimodal (Body)', 'Unimodal (Face)', 'Early Fusion', 'Late Fusion', 'Ensemble']\n",
    "\n",
    "x = np.arange(len(labels)) \n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "rects1 = ax.bar(x - width/2, cnn_auc, width, label='CNN + BiLSTM')\n",
    "rects2 = ax.bar(x + width/2, rnn_auc, width, label='RCNN')\n",
    "\n",
    "ax.set_title('Baseline AUC (Pain Area Classification)')\n",
    "ax.set_xticks(x, labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da59b48ffbe9bcef1efb61bfe80f858fb1e00b0bc963df4742d9d686439143dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('masters-thesis-47ATZEh-')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
