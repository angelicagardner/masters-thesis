{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Results for Binary Classification (pain vs. no pain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, TimeDistributed, Conv1D, BatchNormalization, MaxPooling1D, Bidirectional, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.getcwd() + '\\\\..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.load_dataset import load_dataset, load_fusioned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size = 25, 32\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=48)\n",
    "\n",
    "cnn_auc = []\n",
    "rnn_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM():\n",
    "    def __init__(self, n_features, n_length, n_outputs):\n",
    "        input = Input(shape=(1, n_length, n_features))\n",
    "        conv1d = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'))(input)\n",
    "        maxpool = TimeDistributed(MaxPooling1D(pool_size=2, strides=2, data_format='channels_first'))(conv1d)\n",
    "        flatten = TimeDistributed(Flatten())(maxpool)\n",
    "        lstm = Bidirectional(LSTM(64, activation='relu'))(flatten)\n",
    "        dense = Dense(64, activation='relu')(lstm)\n",
    "        output = Dense(units=n_outputs, activation='softmax')(dense)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=n_outputs, average='macro')])\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, class_weight):\n",
    "        history = self.model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, class_weight=class_weight,verbose=2)\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        results = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        return results\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN():\n",
    "    def __init__(self, n_features, n_length, n_outputs):\n",
    "        input = Input(shape=(1, n_length, n_features))\n",
    "        conv1d = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation=PReLU(alpha_initializer=Constant(value=0.25))))(input)\n",
    "        bn = TimeDistributed(BatchNormalization())(conv1d)\n",
    "        maxpool = TimeDistributed(MaxPooling1D(pool_size=2, strides=2, data_format='channels_first'))(bn)\n",
    "        flatten = Flatten()(maxpool)\n",
    "        dense = Dense(64, activation=PReLU(alpha_initializer=Constant(value=0.25)))(flatten)\n",
    "        output = Dense(units=n_outputs, activation='softmax')(dense)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=n_outputs, average='macro')])\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, class_weight):\n",
    "        history = self.model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, class_weight=class_weight, verbose=2)\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        results = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        return results\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unimodal Body Modality (Skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset('skeleton', binary=True)\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    cnnlstm_multiclass_body_model = CNNLSTM(n_features, n_length, n_outputs)\n",
    "    history = cnnlstm_multiclass_body_model.train(X_train, y_train, X_val, y_val, epochs, batch_size, d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnnlstm_multiclass_body_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = cnnlstm_multiclass_body_model.evaluate(X_test, y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "bal_acc = balanced_accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1)) \n",
    "print('Accuracy: {:.2f}% \\nBalanced Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, bal_acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rcnn_multiclass_body_model = RCNN(n_features, n_length, n_outputs)\n",
    "    history = rcnn_multiclass_body_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size, class_weight=d_class_weights)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rcnn_multiclass_body_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = rcnn_multiclass_body_model.evaluate(X_test, y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "bal_acc = balanced_accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1)) \n",
    "print('Accuracy: {:.2f}% \\nBalanced Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, bal_acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unimodal Face Modality (Action Units + Head Pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset('AUs', binary=True)\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    cnnlstm_binary_face_model = CNNLSTM(n_features, n_length, n_outputs)\n",
    "    history = cnnlstm_binary_face_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnnlstm_binary_face_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = cnnlstm_binary_face_model.evaluate(X_test, y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rcnn_binary_face_model = RCNN(n_features, n_length, n_outputs)\n",
    "    history = rcnn_binary_face_model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rcnn_binary_face_model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = rcnn_binary_face_model.evaluate(X_test, y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multimodal Early Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_fusioned_dataset(binary=True)\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    model = CNNLSTM(n_features, n_length, n_outputs)\n",
    "    history = model.train(X_train, y_train, X_val, y_val, epochs, batch_size)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = model.evaluate(X_test, y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    model = RCNN(n_features, n_length, n_outputs)\n",
    "    history = model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "_, acc, auc, precision, recall, f1 = model.evaluate(X_test, y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multimodal Late Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_X_train, body_X_test, body_y_train, body_y_test = load_dataset('skeleton', binary=True, fusion=True)\n",
    "body_X = body_X_train.copy()\n",
    "body_y = body_y_train.copy()\n",
    "\n",
    "print(body_X_train.shape, body_y_train.shape)\n",
    "print(body_X_test.shape, body_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_X_train, face_X_test, face_y_train, face_y_test = load_dataset('AUs', binary=True)\n",
    "face_X = face_X_train.copy()\n",
    "face_y = face_y_train.copy()\n",
    "\n",
    "print(face_X_train.shape, face_y_train.shape)\n",
    "print(face_X_test.shape, face_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_length, body_features, face_features, n_outputs = face_X_train.shape[2], body_X_train.shape[-1], face_X_train.shape[-1], body_y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusioned_CNNLSTM():\n",
    "    def __init__(self, body_features, face_features, n_length, n_outputs):\n",
    "        input_1 = Input(shape=(1, n_length, body_features))\n",
    "        conv1d_1 = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'))(input_1)\n",
    "        maxpool_1 = TimeDistributed(MaxPooling1D(pool_size=2, data_format='channels_first'))(conv1d_1)\n",
    "        flatten_1 = TimeDistributed(Flatten())(maxpool_1)\n",
    "        lstm_1 = LSTM(64)(flatten_1)\n",
    "        dense_1 = Dense(64, activation='relu')(lstm_1)\n",
    "\n",
    "        input_2 = Input(shape=(1, n_length, face_features))\n",
    "        conv1d_2 = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'))(input_2)\n",
    "        maxpool_2 = TimeDistributed(MaxPooling1D(pool_size=2, data_format='channels_first'))(conv1d_2)\n",
    "        flatten_2 = TimeDistributed(Flatten())(maxpool_2)\n",
    "        lstm_2 = LSTM(64)(flatten_2)\n",
    "        dense_2 = Dense(64, activation='relu')(lstm_2)\n",
    "\n",
    "        concat = Concatenate()([dense_1, dense_2])\n",
    "        output = Dense(units=n_outputs, activation='sigmoid')(concat)\n",
    "        model = Model(inputs=[input_1, input_2], outputs=[output])\n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=n_outputs, average='macro')])\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, body_X_train, face_X_train, y_train, body_X_val, face_X_val, y_val, epochs, batch_size):\n",
    "        history = self.model.fit([body_X_train, face_X_train], y_train, validation_data=([body_X_val, face_X_val], y_val), \n",
    "                            epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, body_X_test, face_X_test, y_test):\n",
    "        results = self.model.evaluate([body_X_test, face_X_test], y_test, verbose=0)\n",
    "        return results\n",
    "\n",
    "    def predict(self, body_X_test, face_X_test):\n",
    "        predictions = self.model.predict([body_X_test, face_X_test])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(body_X):\n",
    "    body_X_train, body_X_val = body_X[train_index], body_X[val_index]\n",
    "    body_y_train, body_y_val = body_y[train_index], body_y[val_index]\n",
    "    face_X_train, face_X_val = face_X[train_index], face_X[val_index]\n",
    "    face_y_train, face_y_val = face_y[train_index], face_y[val_index]\n",
    "    model = fusioned_CNNLSTM(body_features, face_features, n_length, n_outputs)\n",
    "    history = model.train(body_X_train, face_X_train, body_y_train, body_X_val, face_X_val, face_y_val, epochs, batch_size)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(body_X_test, face_X_test)\n",
    "_, acc, auc, precision, recall, f1 = model.evaluate(body_X_test, face_X_test, y_test)\n",
    "cnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusioned_RCNN():\n",
    "    def __init__(self, body_features, face_features, n_length, n_outputs):\n",
    "        input_1 = Input(shape=(1, n_length, body_features))\n",
    "        conv1d_1 = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation=PReLU(alpha_initializer=Constant(value=0.25))))(input_1)\n",
    "        bn_1 = TimeDistributed(BatchNormalization())(conv1d_1)\n",
    "        maxpool_1 = TimeDistributed(MaxPooling1D(pool_size=2, data_format='channels_first'))(bn_1)\n",
    "        flatten_1 = Flatten()(maxpool_1)\n",
    "        dense_1 = Dense(64)(flatten_1)\n",
    "\n",
    "        input_2 = Input(shape=(1, n_length, face_features))\n",
    "        conv1d_2 = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation=PReLU(alpha_initializer=Constant(value=0.25))))(input_2)\n",
    "        bn_2 = TimeDistributed(BatchNormalization())(conv1d_2)\n",
    "        maxpool_2 = TimeDistributed(MaxPooling1D(pool_size=2, data_format='channels_first'))(bn_2)\n",
    "        flatten_2 = Flatten()(maxpool_2)\n",
    "        dense_2 = Dense(64)(flatten_2)\n",
    "\n",
    "        concat = Concatenate()([dense_1, dense_2])\n",
    "        output = Dense(units=n_outputs, activation='sigmoid')(concat)\n",
    "        model = Model(inputs=[input_1, input_2], outputs=[output])\n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=n_outputs, average='macro')])\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, body_X_train, face_X_train, y_train, body_X_val, face_X_val, y_val, epochs, batch_size):\n",
    "        history = self.model.fit([body_X_train, face_X_train], y_train, validation_data=([body_X_val, face_X_val], y_val), \n",
    "                            epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, body_X_test, face_X_test, y_test):\n",
    "        results = self.model.evaluate([body_X_test, face_X_test], y_test, verbose=0)\n",
    "        return results\n",
    "\n",
    "    def predict(self, body_X_test, face_X_test):\n",
    "        predictions = self.model.predict([body_X_test, face_X_test])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(body_X):\n",
    "    body_X_train, body_X_val = body_X[train_index], body_X[val_index]\n",
    "    body_y_train, body_y_val = body_y[train_index], body_y[val_index]\n",
    "    face_X_train, face_X_val = face_X[train_index], face_X[val_index]\n",
    "    face_y_train, face_y_val = face_y[train_index], face_y[val_index]\n",
    "    model = fusioned_RCNN(body_features, face_features, n_length, n_outputs)\n",
    "    history = model.train(body_X_train, face_X_train, body_y_train, body_X_val, face_X_val, face_y_val, epochs, batch_size)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(body_X_test, face_X_test)\n",
    "_, acc, auc, precision, recall, f1 = model.evaluate(body_X_test, face_X_test, body_y_test)\n",
    "rnn_auc.append(round(auc, 2))\n",
    "print('Accuracy: {:.2f}% \\nROC/AUC: {:.2f} \\nPrecision: {:.2f} \\nRecall: {:.2f} \\nF1 score: {:.2f}'.format(acc * 100, auc, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasMember():\n",
    "    def __init__(self, name=None, keras_model=None, train_batches=None,\n",
    "                 val_batches=None, submission_probs=None, keras_modelpath=None,\n",
    "                 keras_kwargs={}):\n",
    "        assert(name is not None)\n",
    "        self.name = name\n",
    "        self.model = keras_model\n",
    "        self.submission_probs = submission_probs\n",
    "        # Initialize Params\n",
    "        self.val_probs = None\n",
    "        self.train_probs = None\n",
    "        self.val_classes = None\n",
    "        self.train_classes = None\n",
    "        if (keras_model is None) and (keras_modelpath is not None):\n",
    "            self.load_kerasmodel(self.keras_modelpath, self.keras_kwargs)\n",
    "        if train_batches is not None:\n",
    "            self._calculate_train_predictions(train_batches)\n",
    "        if val_batches is not None:\n",
    "            self._calculate_val_predictions(val_batches)\n",
    "\n",
    "    def _test_datatuple(self, datatuple):\n",
    "        assert(len(datatuple) == 2)\n",
    "        assert(datatuple[0].shape[0] == datatuple[1].shape[0])\n",
    "\n",
    "    def _calculate_predictions(self, batches):\n",
    "        if hasattr(batches, 'shuffle'):\n",
    "            batches.reset()\n",
    "            batches.shuffle = False\n",
    "        if type(batches) is tuple:\n",
    "            self._test_datatuple(batches)\n",
    "            return self.model.predict(batches[0])\n",
    "        return self.model.predict_generator(\n",
    "            batches, steps=(batches.n // batches.batch_size) + 1, verbose=1)\n",
    "\n",
    "    def _calculate_val_predictions(self, val_batches):\n",
    "        if type(val_batches) is tuple:\n",
    "            self.val_classes = val_batches[1]\n",
    "        elif hasattr(val_batches, 'classes'):\n",
    "            self.val_classes = np.array(val_batches.classes)\n",
    "        elif hasattr(val_batches, 'y'):\n",
    "            self.val_classes = np.array(val_batches.y)\n",
    "        else:\n",
    "            raise ValueError(\"No known class in data batch\")\n",
    "        self.val_probs = self._calculate_predictions(val_batches)\n",
    "        return self.val_probs\n",
    "\n",
    "    def _calculate_train_predictions(self, train_batches):\n",
    "        if type(train_batches) is tuple:\n",
    "            self.train_classes = train_batches[1]\n",
    "        elif hasattr(train_batches, 'classes'):\n",
    "            self.train_classes = np.array(train_batches.classes)\n",
    "        elif hasattr(train_batches, 'y'):\n",
    "            self.train_classes = np.array(train_batches.y)\n",
    "        else:\n",
    "            raise ValueError(\"No known class in data batch\")\n",
    "        self.train_probs = self._calculate_predictions(train_batches)\n",
    "        return self.train_probs\n",
    "\n",
    "\n",
    "def _calculate_metric(y_true, y_pred, metric=None):\n",
    "    if metric is None:\n",
    "        metric = roc_auc_score\n",
    "    y_t = y_true\n",
    "    y_p = y_pred\n",
    "    if metric == roc_auc_score:\n",
    "        return metric(y_t, y_p, multi_class='ovo')\n",
    "    if y_true.ndim > 1:\n",
    "        y_t = np.argmax(y_true, axis=1)\n",
    "    if y_pred.ndim > 1:\n",
    "        y_p = np.argmax(y_pred, axis=1)\n",
    "    if metric is precision_recall_fscore_support:\n",
    "        return precision_recall_fscore_support(y_t, y_p, average='macro')\n",
    "    return metric(y_t, y_p)\n",
    "\n",
    "class DirichletEnsemble():\n",
    "    def __init__(self, N=10000, metric=None, maximize=True):\n",
    "        self.n = N\n",
    "        self.metric = metric\n",
    "        if metric is None:\n",
    "            self.metric = roc_auc_score\n",
    "        self.maximize = maximize\n",
    "        # Initialize Parameters:\n",
    "        self.members = []\n",
    "        self.bestweights = []\n",
    "        self.probabilities = None\n",
    "        self._nmembers = 0\n",
    "        self.bestscore = float(\"-inf\") if maximize else float(\"inf\")\n",
    "        self.accuracy = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.f1 = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def add_members(self, members):\n",
    "        for member in members:\n",
    "            self.add_member(member)\n",
    "\n",
    "    def add_member(self, member):\n",
    "        self.members.append(member)\n",
    "        self._nmembers += 1\n",
    "\n",
    "    def fit(self, verbose=False):\n",
    "        assert(len(self.members) > 1)\n",
    "        val_classes = self.members[0].val_classes\n",
    "        best_ensemble_score = float(\"-inf\") if self.maximize else float(\"inf\")\n",
    "        best_ensemble_accuracy = 0\n",
    "        best_ensemble_p = 0\n",
    "        best_ensemble_r = 0\n",
    "        best_ensemble_f1 = 0\n",
    "        rsbest = None\n",
    "        for i in range(self.n):\n",
    "            rs = np.random.dirichlet(np.ones(self._nmembers), size=1)[0]\n",
    "            preds = np.sum(np.array([self.members[i].val_probs * rs[i]\n",
    "                                     for i in range(self._nmembers)]), axis=0)\n",
    "            ensemble_score = _calculate_metric(val_classes, preds)\n",
    "            ensemble_accuracy = _calculate_metric(val_classes, preds, accuracy_score)\n",
    "            ensemble_prf1 = _calculate_metric(val_classes, preds, precision_recall_fscore_support)\n",
    "            ensemble_p = ensemble_prf1[0]\n",
    "            ensemble_r = ensemble_prf1[1]\n",
    "            ensemble_f1 = ensemble_prf1[2]\n",
    "            max_flag = self.maximize and ensemble_score > best_ensemble_score\n",
    "            min_flag = not(\n",
    "                self.maximize) and ensemble_score < best_ensemble_score\n",
    "            if max_flag or min_flag:\n",
    "                if verbose:\n",
    "                    print(ensemble_score, i, rs) \n",
    "                best_ensemble_score = ensemble_score\n",
    "                rsbest = rs\n",
    "            if ensemble_accuracy > best_ensemble_accuracy:\n",
    "                if verbose:\n",
    "                    print(ensemble_accuracy, i, rs) \n",
    "                best_ensemble_accuracy = ensemble_accuracy\n",
    "            if ensemble_p > best_ensemble_p:\n",
    "                if verbose:\n",
    "                    print(ensemble_p, i, rs) \n",
    "                best_ensemble_p = ensemble_p\n",
    "            if ensemble_r > best_ensemble_r:\n",
    "                if verbose:\n",
    "                    print(ensemble_r, i, rs) \n",
    "                best_ensemble_r = ensemble_r\n",
    "            if ensemble_f1 > best_ensemble_f1:\n",
    "                if verbose:\n",
    "                    print(ensemble_f1, i, rs) \n",
    "                best_ensemble_f1 = ensemble_f1\n",
    "        self.bestweights = rsbest\n",
    "        self.bestscore = best_ensemble_score\n",
    "        self.accuracy = best_ensemble_accuracy\n",
    "        self.precision = best_ensemble_p\n",
    "        self.recall = best_ensemble_r\n",
    "        self.f1 = best_ensemble_f1\n",
    "\n",
    "    def predict(self):\n",
    "        self.probabilities = np.sum(np.array([self.bestweights[i] *\n",
    "                                              self.members[i].submission_probs\n",
    "                                              for i in range(self._nmembers)]),\n",
    "                                    axis=0)\n",
    "        return self.probabilities\n",
    "        \n",
    "    def describe(self):\n",
    "        for i in range(self._nmembers):\n",
    "            member = self.members[i]\n",
    "            text = member.name + \" (weight: {:1.4f})\".format(self.bestweights[i])\n",
    "            print(text)\n",
    "        print(\"Accuracy: {:1.2f}% - ROC/AUC: {:1.2f} - Precision: {:1.2f} - Recall: {:1.2f} - F1 score: {:1.2f}\".format(\n",
    "            self.accuracy * 100, self.bestscore, self.precision, self.recall, self.f1))\n",
    "        return self.bestscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnlstm_body_member = KerasMember(name=\"CNN + Bidirectional LSTM Body Model\", keras_model=cnnlstm_binary_body_model, train_batches=(body_X_train, y_train), val_batches=(body_X_test, body_y_test))\n",
    "rcnn_body_member = KerasMember(name=\"RCNN Body Model\", keras_model=rcnn_binary_body_model, train_batches=(body_X_train, body_y_train), val_batches=(body_X_test, body_y_test))\n",
    "cnnlstm_face_member = KerasMember(name=\"CNN + Bidirectional LSTM Face Model\", keras_model=cnnlstm_binary_face_model, train_batches=(face_X_train, face_y_train), val_batches=(face_X_test, face_y_test))\n",
    "rcnn_face_member = KerasMember(name=\"RCNN Face Model\", keras_model=rcnn_binary_face_model, train_batches=(face_X_train, face_y_train), val_batches=(face_X_test, face_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichletEnsemble = DirichletEnsemble()\n",
    "dirichletEnsemble.add_member(cnnlstm_body_member)\n",
    "dirichletEnsemble.add_member(rcnn_body_member)\n",
    "dirichletEnsemble.add_member(cnnlstm_face_member)\n",
    "dirichletEnsemble.add_member(rcnn_face_member)\n",
    "dirichletEnsemble.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = dirichletEnsemble.describe()\n",
    "cnn_auc.append(round(e, 2))\n",
    "rnn_auc.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Unimodal (Body)', 'Unimodal (Face)', 'Early Fusion', 'Late Fusion', 'Ensemble']\n",
    "men_means = cnn_auc\n",
    "women_means = rnn_auc\n",
    "\n",
    "x = np.arange(len(labels)) \n",
    "width = 0.35 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='CNN + BiLSTM')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='RCNN')\n",
    "\n",
    "ax.set_title('Baseline AUC (Binary Classification)')\n",
    "ax.set_xticks(x, labels)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "225abd0b4b41c85229fb7285a24282bb8b7c5c494a1c5011beaea88d2c1fa3cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('masters-thesis-dSEc-4wZ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
