{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (Pain Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, TimeDistributed, Conv1D, BatchNormalization, MaxPooling1D, Bidirectional, Concatenate, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.getcwd() + '\\\\..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.data.load_dataset import load_dataset\n",
    "from src.lib.time_series_augmentation.utils.augmentation import jitter, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [64, 128, 256, 512]\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "kernel_size = [3, 5]\n",
    "learning_rate = [0.001, 0.0001, 0.00001]\n",
    "optimizer = ['Adam', 'RMSprop', 'Nadam']\n",
    "dropout = [0.0, 0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unimodal Body Modality (Skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset('skeleton', binary=True)\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_X = jitter(X, sigma=0.03)\n",
    "reshaped_X = X.reshape((X.shape[0], X.shape[2], X.shape[-1]))\n",
    "rotated_X = rotation(reshaped_X)\n",
    "rotated_X = rotated_X.reshape((rotated_X.shape[0], 1, rotated_X.shape[1], rotated_X.shape[-1]))\n",
    "augmented_X = np.concatenate((rotated_X[0:200], jitter_X[0:200]), axis=0)\n",
    "add_y = np.concatenate((y[0:200], y[0:200]), axis=0)\n",
    "full_X = np.concatenate((augmented_X, X), axis=0)\n",
    "full_y = np.concatenate((add_y, y), axis=0)\n",
    "full_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM():\n",
    "    def __init__(self, n_features, n_length, n_outputs, units, activation, kernel_size, learning_rate, optimizer, dropout):\n",
    "        if optimizer == 'Adam':\n",
    "            ops = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif optimizer == 'RMSprop':\n",
    "            ops = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "        elif optimizer == 'Nadam':\n",
    "            ops = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "        input = Input(shape=(1, n_length, n_features))\n",
    "        conv1d_1 = Conv1D(filters=units, kernel_size=kernel_size,\n",
    "                          activation=activation)(input)\n",
    "        bn_1 = BatchNormalization()(conv1d_1)\n",
    "        conv1d_2 = Conv1D(filters=units, kernel_size=kernel_size,\n",
    "                          activation=activation)(bn_1)\n",
    "        maxpool_1 = TimeDistributed(MaxPooling1D(\n",
    "            pool_size=2, strides=2, data_format='channels_first'))(conv1d_2)\n",
    "        lstm_1 = TimeDistributed(Bidirectional(\n",
    "            LSTM(units=units, return_sequences=True)))(maxpool_1)\n",
    "        lstm_2 = TimeDistributed(Bidirectional(LSTM(units=units)))(lstm_1)\n",
    "        flatten = Flatten()(lstm_2)\n",
    "        dense_1 = Dense(units, activation=activation)(flatten)\n",
    "        dropout_1 = Dropout(dropout)(dense_1)\n",
    "        dense_2 = Dense(units, activation=activation)(dropout_1)\n",
    "        output = Dense(units=n_outputs, activation='sigmoid')(dense_2)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=ops, metrics=['accuracy'])\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs):\n",
    "        history = self.model.fit(X_train, y_train, validation_data=(\n",
    "            X_val, y_val), epochs=epochs, batch_size=32, callbacks=[early_stopping], verbose=2)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "body_cnnlstm_values = { 'units': 0, 'activation': '', 'kernel_size': 0, 'learning_rate' : 0.0, 'optimizer': '', 'dropout': 0.0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in units:\n",
    "    for a in activations:\n",
    "        for k in kernel_size:\n",
    "            for l in learning_rate:\n",
    "                for o in optimizer:\n",
    "                    for d in dropout:\n",
    "                        print('\\nUnits:', u, 'Activation:', a, 'Kernel size:', k, 'Learning rate:', l, 'Optimizer:', o, 'Dropout:', d)\n",
    "                        for train_index, val_index in kf.split(full_X):\n",
    "                            X_train, X_val = full_X[train_index], full_X[val_index]\n",
    "                            y_train, y_val = full_y[train_index], full_y[val_index]\n",
    "                            model = CNNLSTM(n_features, n_length, n_outputs, u, a, k, l, o, d)\n",
    "                            history = model.train(X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "                            if (history.history['val_accuracy'][-1] > best_acc):\n",
    "                                best_acc = history.history['val_accuracy'][-1]\n",
    "                                body_cnnlstm_values = { 'units': u, 'activation': a, 'kernel_size': k, 'learning_rate' : l, 'optimizer': o, 'dropout': d }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)\n",
    "print(body_cnnlstm_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN():\n",
    "    def __init__(self, n_features, n_length, n_outputs, units, kernel_size, learning_rate, optimizer, dropout):\n",
    "        if optimizer == 'Adam':\n",
    "            ops = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif optimizer == 'RMSprop':\n",
    "            ops = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "        elif optimizer == 'Nadam':\n",
    "            ops = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "        input = Input(shape=(1, n_length, n_features))\n",
    "        conv1 = Conv1D(filters=units, kernel_size=kernel_size, padding='same')\n",
    "        stack1 = conv1(input)\n",
    "        stack2 = BatchNormalization()(stack1)\n",
    "        stack3 = PReLU()(stack2)\n",
    "        conv2 = Conv1D(filters=units, kernel_size=kernel_size,\n",
    "                       padding='same', kernel_initializer='he_normal')\n",
    "        stack4 = conv2(stack3)\n",
    "        stack5 = Concatenate()([stack1, stack4])\n",
    "        stack6 = BatchNormalization()(stack5)\n",
    "        stack7 = PReLU()(stack6)\n",
    "        conv3 = Conv1D(filters=units, kernel_size=kernel_size,\n",
    "                       padding='same')\n",
    "        stack8 = conv3(stack7)\n",
    "        stack9 = Concatenate()([stack1, stack8])\n",
    "        stack10 = BatchNormalization()(stack9)\n",
    "        stack11 = PReLU()(stack10)\n",
    "        stack12 = TimeDistributed(MaxPooling1D(\n",
    "            (2), strides=2, data_format='channels_first'))(stack11)\n",
    "        stack13 = Dropout(dropout)(stack12)\n",
    "        flatten = Flatten()(stack13)\n",
    "        output = Dense(units=n_outputs, activation='sigmoid')(flatten)\n",
    "        model = Model(inputs=input, outputs=output)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=ops, metrics=['accuracy'])\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
    "        history = self.model.fit(X_train, y_train, validation_data=(\n",
    "            X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[self.early_stopping], verbose=2)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "body_rcnn_values = { 'units': 0, 'kernel_size': 0, 'learning_rate' : 0.0, 'optimizer': '', 'dropout': 0.0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in units:\n",
    "    for k in kernel_size:\n",
    "        for l in learning_rate:\n",
    "            for o in optimizer:\n",
    "                for d in dropout:\n",
    "                    print('\\nUnits:', u, 'Kernel size:', k, 'Learning rate:', l, 'Optimizer:', o, 'Dropout:', d)\n",
    "                    for train_index, val_index in kf.split(full_X):\n",
    "                        X_train, X_val = full_X[train_index], full_X[val_index]\n",
    "                        y_train, y_val = full_y[train_index], full_y[val_index]\n",
    "                        model = RCNN(n_features, n_length, n_outputs, u, k, l, o, d)\n",
    "                        history = model.train(X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "                        if (history.history['val_accuracy'][-1] > best_acc):\n",
    "                            best_acc = history.history['val_accuracy'][-1]\n",
    "                            body_rcnn_values = { 'units': u, 'kernel_size': k, 'learning_rate' : l, 'optimizer': o, 'dropout': d }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)\n",
    "print(body_rcnn_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unimodal Face modality (Action units + Head pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset('AUs', binary=True)\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "n_length, n_features, n_outputs = X_train.shape[2], X_train.shape[-1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_X = jitter(X, sigma=0.03)\n",
    "reshaped_X = X.reshape((X.shape[0], X.shape[2], X.shape[-1]))\n",
    "rotated_X = rotation(reshaped_X)\n",
    "rotated_X = rotated_X.reshape((rotated_X.shape[0], 1, rotated_X.shape[1], rotated_X.shape[-1]))\n",
    "augmented_X = np.concatenate((rotated_X[0:200], jitter_X[0:200]), axis=0)\n",
    "add_y = np.concatenate((y[0:200], y[0:200]), axis=0)\n",
    "full_X = np.concatenate((augmented_X, X), axis=0)\n",
    "full_y = np.concatenate((add_y, y), axis=0)\n",
    "full_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "face_cnnlstm_values = { 'units': 0, 'activation': '', 'kernel_size': 0, 'learning_rate' : 0.0, 'optimizer': '', 'dropout': 0.0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in units:\n",
    "    for a in activations:\n",
    "        for k in kernel_size:\n",
    "            for l in learning_rate:\n",
    "                for o in optimizer:\n",
    "                    for d in dropout:\n",
    "                        print('\\nUnits:', u, 'Activation:', a, 'Kernel size:', k, 'Learning rate:', l, 'Optimizer:', o, 'Dropout:', d)\n",
    "                        for train_index, val_index in kf.split(full_X):\n",
    "                            X_train, X_val = full_X[train_index], full_X[val_index]\n",
    "                            y_train, y_val = full_y[train_index], full_y[val_index]\n",
    "                            model = CNNLSTM(n_features, n_length, n_outputs, u, a, k, l, o, d)\n",
    "                            history = model.train(X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "                            if (history.history['val_accuracy'][-1] > best_acc):\n",
    "                                best_acc = history.history['val_accuracy'][-1]\n",
    "                                face_cnnlstm_values = { 'units': u, 'activation': a, 'kernel_size': k, 'learning_rate' : l, 'optimizer': o, 'dropout': d }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)\n",
    "print(face_cnnlstm_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "face_rcnn_values = { 'units': 0, 'kernel_size': 0, 'learning_rate' : 0.0, 'optimizer': '', 'dropout': 0.0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in units:\n",
    "    for k in kernel_size:\n",
    "        for l in learning_rate:\n",
    "            for o in optimizer:\n",
    "                for d in dropout:\n",
    "                    print('\\nUnits:', u, 'Kernel size:', k, 'Learning rate:', l, 'Optimizer:', o, 'Dropout:', d)\n",
    "                    for train_index, val_index in kf.split(full_X):\n",
    "                        X_train, X_val = full_X[train_index], full_X[val_index]\n",
    "                        y_train, y_val = full_y[train_index], full_y[val_index]\n",
    "                        model = RCNN(n_features, n_length, n_outputs, u, k, l, o, d)\n",
    "                        history = model.train(X_train, y_train, X_val, y_val, epochs=epochs)\n",
    "                        if (history.history['val_accuracy'][-1] > best_acc):\n",
    "                            best_acc = history.history['val_accuracy'][-1]\n",
    "                            face_rcnn_values = { 'units': u, 'kernel_size': k, 'learning_rate' : l, 'optimizer': o, 'dropout': d }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)\n",
    "print(face_rcnn_values)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da59b48ffbe9bcef1efb61bfe80f858fb1e00b0bc963df4742d9d686439143dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('masters-thesis-47ATZEh-')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
